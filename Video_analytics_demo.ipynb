{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "###### Step 1: Select Target - bounding box \n",
    "###### Step 2: Select target to scale\n",
    "###### Step 3: Select fixed target to remove camera shake"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:24:48.756047Z",
     "start_time": "2024-06-23T00:24:48.752055Z"
    }
   },
   "source": [
    "#Import Dependencies\n",
    "\n",
    "import cv2\n",
    "import cv2.legacy\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('bmh')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:24:48.803393Z",
     "start_time": "2024-06-23T00:24:48.800404Z"
    }
   },
   "source": [
    "#Input demo video name.\n",
    "video_fileName = 'demo.mp4'"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and select tracking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:24:48.809183Z",
     "start_time": "2024-06-23T00:24:48.804799Z"
    }
   },
   "source": [
    "(major_ver, minor_ver, subminor_ver) = cv2.__version__.split('.')\n",
    "\n",
    "#Define bounding box centroid\n",
    "centroids_arr = []\n",
    "\n",
    "#Choose tracker - depends on type of application and type of movement to track (high frequency, big amplitude, etc...)\n",
    "\n",
    "tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "tracker_type = tracker_types[4]\n",
    "\n",
    "if tracker_type == 'BOOSTING':\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "if tracker_type == 'MIL':\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "if tracker_type == 'KCF':\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "if tracker_type == 'TLD':\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "if tracker_type == 'MEDIANFLOW':\n",
    "    tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "if tracker_type == 'GOTURN':\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "if tracker_type == 'MOSSE':\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "if tracker_type == \"CSRT\":\n",
    "    tracker = cv2.TrackerCSRT_create()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Bounding Box Function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:24:48.816501Z",
     "start_time": "2024-06-23T00:24:48.810177Z"
    }
   },
   "source": [
    "#DEFINE TRACKING BOX & CENTROID function \n",
    "\n",
    "def track_box(video_fileName):\n",
    "    \n",
    "    '''\n",
    "    a function that returns list of object centroids across frames\n",
    "    '''\n",
    "    \n",
    "   \n",
    "    # Read video\n",
    "    video = cv2.VideoCapture(video_fileName)\n",
    "\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    "        \n",
    "        \n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print ('Cannot read video file')\n",
    "        sys.exit()\n",
    "\n",
    "#     # Define an initial bounding box X,Y,dX,dy\n",
    "#     bbox = (287, 23, 86, 320)\n",
    "\n",
    "    # OR user-defined bounding box\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    "    \n",
    "    # Start clock cycles\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    while True:\n",
    "        #Define centroid of bbox\n",
    "        centroid = int(bbox[0]+bbox[2]/2), int(bbox[1] + bbox[3] /2)\n",
    "        centroids_arr.append(centroid)\n",
    "\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        if not ok:\n",
    "            break\n",
    "            \n",
    "        # Get frames per second\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    "\n",
    "        # Calculate Time\n",
    "        Time = (cv2.getTickCount() - timer)/cv2.getTickFrequency();\n",
    "        \n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "        # Display on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "        cv2.putText(frame, \"Timer: \" + str(int(Time)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    "        #cv2.putText(frame, \"Frames/sec : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    "        \n",
    "        # Display result\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return centroids_arr, fps"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:04.087724Z",
     "start_time": "2024-06-23T00:24:48.828480Z"
    }
   },
   "source": [
    "#Define centroid array based on track box definition\n",
    "centroids_arr, fps = track_box(video_fileName)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:04.096779Z",
     "start_time": "2024-06-23T00:29:04.091684Z"
    }
   },
   "source": [
    "#Extract x and y of track box centroid\n",
    "x_1= np.array(centroids_arr)[:,0]\n",
    "y_1= np.array(centroids_arr)[:,1] "
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize axes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:04.107174Z",
     "start_time": "2024-06-23T00:29:04.098769Z"
    }
   },
   "source": [
    "from __future__ import division"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.811696Z",
     "start_time": "2024-06-23T00:29:04.109163Z"
    }
   },
   "source": [
    "#Initialize video again to get dimensions from first frame    \n",
    "    \n",
    "    # Read video\n",
    "video = cv2.VideoCapture(video_fileName)\n",
    "    # Read first frame.\n",
    "ok, frame = video.read()\n",
    "    # Select normalizing bbox\n",
    "bbox_norm = cv2.selectROI(frame, False)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.818671Z",
     "start_time": "2024-06-23T00:29:06.813688Z"
    }
   },
   "source": [
    "x_len = bbox_norm[2]\n",
    "y_len = bbox_norm[3]\n",
    "real_x = 5 #in --> Change this depending on selected target\n",
    "#real_y= ...  #in --> only use if we're working with y axis scale, otherwise put sy=sx\n",
    "sx=real_x/x_len\n",
    "sy=sx"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.837278Z",
     "start_time": "2024-06-23T00:29:06.820276Z"
    }
   },
   "source": [
    "#Convert X axis into seconds\n",
    "x_axis = np.arange(len(x_1))/fps"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract x and y arrays from centroids series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot movement on `x` axis "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.950676Z",
     "start_time": "2024-06-23T00:29:06.838270Z"
    }
   },
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(x_axis,x_1*sx)\n",
    "plt.title('Target Lateral Displacement')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (Inches)')"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Camera Shake - Fixed target"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.956414Z",
     "start_time": "2024-06-23T00:29:06.951668Z"
    }
   },
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('bmh')"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.960340Z",
     "start_time": "2024-06-23T00:29:06.957405Z"
    }
   },
   "source": [
    "video_fileName = 'demo.mp4'"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.966315Z",
     "start_time": "2024-06-23T00:29:06.962328Z"
    }
   },
   "source": [
    "'''\n",
    "initilising and selecting tracking algorithm\n",
    "\n",
    "'''\n",
    "(major_ver, minor_ver, subminor_ver) = cv2.__version__.split('.')\n",
    "\n",
    "centroids_arr= []\n",
    "\n",
    "tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "tracker_type = tracker_types[4]\n",
    "\n",
    "# if int(minor_ver) < 3:\n",
    "#     tracker = cv2.Tracker_create(tracker_type)\n",
    "# else:\n",
    "if tracker_type == 'BOOSTING':\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "if tracker_type == 'MIL':\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "if tracker_type == 'KCF':\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "if tracker_type == 'TLD':\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "if tracker_type == 'MEDIANFLOW':\n",
    "    tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "if tracker_type == 'GOTURN':\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "if tracker_type == 'MOSSE':\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "if tracker_type == \"CSRT\":\n",
    "    tracker = cv2.TrackerCSRT_create()"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:06.973861Z",
     "start_time": "2024-06-23T00:29:06.967311Z"
    }
   },
   "source": [
    "#DEFINE TRACKING BOX & CENTROID function for FIXED TARGET\n",
    "\n",
    "def track_box(video_fileName):\n",
    "    \n",
    "    '''\n",
    "    a function that returns list of object centroids across frames\n",
    "    '''\n",
    "\n",
    "    # Read video\n",
    "    video = cv2.VideoCapture(video_fileName)\n",
    "\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print ('Cannot read video file')\n",
    "        sys.exit()\n",
    "\n",
    "    # OR user-defined bounding box\n",
    "    bbox_fixed = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox_fixed)\n",
    "\n",
    "    while True:\n",
    "        #Define centroid of bbox\n",
    "        centroid = int(bbox_fixed[0]+bbox_fixed[2]/2), int(bbox_fixed[1] + bbox_fixed[3] /2)\n",
    "        centroids_arr.append(centroid)\n",
    "\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox_fixed = tracker.update(frame)\n",
    "\n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox_fixed[0]), int(bbox_fixed[1]))\n",
    "            p2 = (int(bbox_fixed[0] + bbox_fixed[2]), int(bbox_fixed[1] + bbox_fixed[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "        # Display tracker type on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "\n",
    "        # Display result\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return centroids_arr\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.598239Z",
     "start_time": "2024-06-23T00:29:06.974849Z"
    }
   },
   "source": [
    "#Define centroid array based on track box definition\n",
    "centroids_arr = track_box(video_fileName)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.608132Z",
     "start_time": "2024-06-23T00:29:16.602740Z"
    }
   },
   "source": [
    "#Extract x and y of track box centroid for fixed target\n",
    "x_fixed= np.array(centroids_arr)[:,0]\n",
    "y_fixed= np.array(centroids_arr)[:,1] "
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.719967Z",
     "start_time": "2024-06-23T00:29:16.609125Z"
    }
   },
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(x_axis,x_fixed*sx)\n",
    "plt.title('Camera Lateral Displacement')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (in)')"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displacement with NO Camera Shake"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.723548Z",
     "start_time": "2024-06-23T00:29:16.720962Z"
    }
   },
   "source": [
    "# Get Displacement with no Camera shake = Coordinates wrt to new origin, fixed object. use absolute values\n",
    "x1= np.abs(np.subtract(x_1,x_fixed))\n",
    "y1= np.abs(np.subtract(y_1,y_fixed))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.816206Z",
     "start_time": "2024-06-23T00:29:16.723548Z"
    }
   },
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(x_axis,(x1*sx))\n",
    "plt.title('Target Compensated Lateral Displacement')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (in)')"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing Signal -> Apply Low-Pass Filter to remove noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:16.821201Z",
     "start_time": "2024-06-23T00:29:16.817203Z"
    }
   },
   "source": [
    "DURATION=len(x_axis)/fps   #Duration of signal (unit in seconds)\n",
    "SAMPLE_RATE=fps            #Sample rate is frames per second of the video\n",
    "N=DURATION*SAMPLE_RATE     #Number of samples (or total number of frames)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:17.179982Z",
     "start_time": "2024-06-23T00:29:16.822189Z"
    }
   },
   "source": [
    "#Apply low-pass filter\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, nyq_freq, order=4):\n",
    "    normal_cutoff = float(cutoff) / nyq_freq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq, nyq_freq, order=4):\n",
    "    b, a = butter_lowpass(cutoff_freq, nyq_freq, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Filter signal x, result stored to y: \n",
    "cutoff_frequency =3\n",
    "a_xf= butter_lowpass_filter(x1*sx, cutoff_frequency, SAMPLE_RATE/2)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(x_axis,x1*sx, color='red', label=\"Original signal\")\n",
    "plt.plot(x_axis,a_xf, color='blue', label=\"Filtered low-pass with cutoff frequency of {} Hz\".format(cutoff_frequency))\n",
    "#plt.plot(diff, color='gray', label=\"What has been removed\")\n",
    "plt.title(\"Compensated Filtered Lateral displacement\")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (inches)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:17.271492Z",
     "start_time": "2024-06-23T00:29:17.180977Z"
    }
   },
   "source": [
    "# Difference acts as a special high-pass from a reversed butterworth filter. \n",
    "diffx = np.array(x1*sx)-np.array(a_xf)\n",
    "\n",
    "#Plot noise\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(diffx, color='gray', label=\"What has been removed\")"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:17.275477Z",
     "start_time": "2024-06-23T00:29:17.272487Z"
    }
   },
   "source": [],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:29:17.277936Z",
     "start_time": "2024-06-23T00:29:17.275477Z"
    }
   },
   "source": [],
   "execution_count": 25,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
